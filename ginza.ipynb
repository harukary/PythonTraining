{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GiNZA\r\n",
    "* 形態素解析\r\n",
    "* 係り受け関係解析"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import spacy\r\n",
    "nlp = spacy.load(\"ja_ginza\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# パイプライン構成\r\n",
    "for p in nlp.pipeline:\r\n",
    "    print(p)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('tagger', <spacy.pipeline.pipes.Tagger object at 0x000001CE4836BFD0>)\n",
      "('parser', <spacy.pipeline.pipes.DependencyParser object at 0x000001CE561D9040>)\n",
      "('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x000001CE561D90A0>)\n",
      "('CompoundSplitter', <ginza.compound_splitter.CompoundSplitter object at 0x000001CE483F0B20>)\n",
      "('BunsetuRecognizer', <ginza.bunsetu_recognizer.BunsetuRecognizer object at 0x000001CE4836F1F0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "doc = nlp(\"ひき肉に、炒めて冷ましたたまねぎ、パン粉と牛乳と卵を混ぜる。\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 形態素解析結果\r\n",
    "for sent in doc.sents:\r\n",
    "    for token in sent:\r\n",
    "        print(token.i, token.orth_, token.lemma_, token.pos_, token.dep_, token.head.i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 ひき肉 ひき肉 NOUN obl 15\n",
      "1 に に ADP case 0\n",
      "2 、 、 PUNCT punct 0\n",
      "3 炒め 炒める VERB advcl 5\n",
      "4 て て SCONJ mark 3\n",
      "5 冷まし 冷ます VERB acl 7\n",
      "6 た た AUX aux 5\n",
      "7 たまねぎ たまねぎ NOUN obl 15\n",
      "8 、 、 PUNCT punct 7\n",
      "9 パン粉 パン粉 NOUN nmod 11\n",
      "10 と と ADP case 9\n",
      "11 牛乳 牛乳 NOUN nmod 13\n",
      "12 と と ADP case 11\n",
      "13 卵 卵 NOUN obj 15\n",
      "14 を を ADP case 13\n",
      "15 混ぜる 混ぜる VERB ROOT 15\n",
      "16 。 。 PUNCT punct 15\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Token\r\n",
    "print('token-----------------------')\r\n",
    "for token in doc:\r\n",
    "  print(token.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "token-----------------------\n",
      "ひき肉\n",
      "に\n",
      "、\n",
      "炒め\n",
      "て\n",
      "冷まし\n",
      "た\n",
      "たまねぎ\n",
      "、\n",
      "パン粉\n",
      "と\n",
      "牛乳\n",
      "と\n",
      "卵\n",
      "を\n",
      "混ぜる\n",
      "。\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 名詞句のみ抽出\r\n",
    "print('noun-----------------------')\r\n",
    "for np in doc.noun_chunks:\r\n",
    "  print(np)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "noun-----------------------\n",
      "ひき肉\n",
      "炒めて冷ましたたまねぎ\n",
      "パン粉\n",
      "牛乳\n",
      "卵\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 固有表現\r\n",
    "print('ner-----------------------')\r\n",
    "for ent in doc.ents:\r\n",
    "  print(ent.text, ent.start_char, ent.end_char, ent.label_)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ner-----------------------\n",
      "たまねぎ 12 16 Food_Other\n",
      "パン粉 17 20 Food_Other\n",
      "牛乳 21 23 Food_Other\n",
      "卵 24 25 Food_Other\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "token = doc[3]\r\n",
    "print(token)\r\n",
    "print(token.vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "炒め\n",
      "[ 0.08003599 -0.12529491  0.41058803 -0.02664721  0.04041548  0.78141636\n",
      " -0.23311277 -0.15073359  0.00955659 -0.5930606   0.34050038  0.1425334\n",
      "  0.15794998  0.37364605 -0.00280757 -0.24731137 -0.01622627 -0.17575407\n",
      "  0.01014467 -0.10829065  0.25691915 -0.12080216  0.42548573 -0.02411346\n",
      " -0.26828995 -0.18496107 -0.5363033  -0.4052623  -0.20796864 -0.30658633\n",
      " -0.31856316  0.00177421 -0.04962981  0.05581473 -0.05198637 -0.28166738\n",
      " -0.07354025 -0.3067308   0.21216145 -0.18416476  0.2317572   0.06086055\n",
      " -0.1618108  -0.04066261 -0.38274658  0.18726656  0.09697241 -0.2505903\n",
      "  0.09599299 -0.14393942  0.07186734  0.0893968   0.03575384  0.08354529\n",
      "  0.04762713 -0.20661603 -0.07874399  0.30610913  0.2903996   0.11178256\n",
      "  0.7722146   0.36745065  0.1812581  -0.06288622  0.13886492 -0.02742447\n",
      " -0.39427     0.14513959 -0.19134343  0.3100792  -0.29103965 -0.0797707\n",
      "  0.17663671  0.1252554  -0.20718798  0.27784345 -0.19509515 -0.20669697\n",
      "  0.07982596  0.01060199  0.08014685 -0.20495123 -0.08301339  0.33676136\n",
      " -0.10970467  0.21947838  0.87412447 -0.61549586  0.50828725 -0.18165748\n",
      "  0.28879175 -0.12552693  0.18036455  0.10914507  0.11133483  0.45579812\n",
      "  0.5137496   0.21391082  0.16876295  0.58279383 -0.17135848 -0.06699346\n",
      "  0.147866   -0.30884117 -0.1413366   0.1447854  -0.09523503  0.37920326\n",
      "  0.15273765 -0.05269223 -0.45487982 -0.23117658  0.6517125   0.194911\n",
      " -0.04640029 -0.27899262 -0.36831975  0.28282988  0.31100917 -0.37959006\n",
      " -0.0442554   0.0407742   0.25812036  0.02688735 -0.09798232 -0.06215126\n",
      "  0.15590157  0.15490012  0.00104737  0.25288442 -0.14592357 -0.36743802\n",
      " -0.12931636  0.32628888  0.02922744  0.35790777 -0.16169105 -0.26098326\n",
      "  0.21964836 -0.32755065 -0.06228589 -0.17844108 -0.0517545  -0.4895309\n",
      " -0.3835044  -0.15695074 -0.35654035  0.08075377  0.37535924 -0.10261175\n",
      " -0.28273642 -0.01194124 -0.20595735  0.00739032 -0.49823105  0.32092184\n",
      " -0.03709406 -0.23257281  0.00215047  0.82094216 -0.27677962  0.42563725\n",
      " -0.26719025  0.13139014 -0.33242866 -0.13164543  0.01213065 -0.48736563\n",
      " -0.379784   -0.36155018 -0.06186963 -0.21800803  0.2621083  -0.1930803\n",
      " -0.18295832  0.15956159 -0.33356893  0.19229355  0.00516803  0.44406497\n",
      "  0.06836274  0.02844944  0.10156331  0.48476887  0.15491045 -0.06079005\n",
      " -0.11458332  0.39890173  0.15029983  0.0634398  -0.00916071 -0.17972614\n",
      " -0.54247236  0.21851383 -0.3442537  -0.16135557 -0.05807582 -0.09233183\n",
      "  0.18235092  0.03614866 -0.36061916 -0.32246006 -0.4679678   0.14401296\n",
      "  0.2811131   0.40307572  0.3568737   0.14113031  0.30188584 -0.04782851\n",
      " -0.11142699 -0.32850277 -0.06361902 -0.11939589  0.04384028  0.48267075\n",
      "  0.17845081  0.11487152 -0.33651295  0.03232148 -0.0901113  -0.71276796\n",
      "  0.01984897  0.3069034   0.14859377 -0.30999744  0.09960829 -0.10607105\n",
      "  0.10394561  0.05933608  0.08468559  0.31131196  0.371413    0.15818103\n",
      " -0.00502261 -0.01400588  0.17096075  0.41509706 -0.09650114  0.05368846\n",
      "  0.19571657  0.45643744 -0.2270958   0.20155333 -0.2575195  -0.33906975\n",
      "  0.1865203  -0.23846713 -0.00848424 -0.07010636 -0.12163121  0.50894904\n",
      "  0.14650533  0.28015512  0.20219858 -0.10510381  0.11416776 -0.6640258\n",
      "  0.58714205 -0.19332173  0.26288757  0.2862053   0.140424    0.69828063\n",
      "  0.15236357  0.32874918 -0.27889958 -0.12516402 -0.04230369 -0.21123812\n",
      "  0.36830574  0.14466895  0.07190903 -0.03705399 -0.12430517 -0.25101098\n",
      " -0.04033519 -0.21056022  0.50626016  0.33013105 -0.47436962 -0.05575546\n",
      " -0.40049294  0.32097352  0.05157278 -0.0260973  -0.20139831  0.08696187\n",
      "  0.4490269  -0.05321052 -0.29156387  0.08571155  0.05183061  0.42766365\n",
      "  0.01349372  0.45254493  0.304076   -0.24617903  0.01391126  0.3111292 ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(help(doc))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on Doc object:\n",
      "\n",
      "class Doc(builtins.object)\n",
      " |  A sequence of Token objects. Access sentences and named entities, export\n",
      " |  annotations to numpy arrays, losslessly serialize to compressed binary\n",
      " |  strings. The `Doc` object holds an array of `TokenC` structs. The\n",
      " |  Python-level `Token` and `Span` objects are views of this array, i.e.\n",
      " |  they don't own the data themselves.\n",
      " |  \n",
      " |  EXAMPLE:\n",
      " |      Construction 1\n",
      " |      >>> doc = nlp(u'Some text')\n",
      " |  \n",
      " |      Construction 2\n",
      " |      >>> from spacy.tokens import Doc\n",
      " |      >>> doc = Doc(nlp.vocab, words=[u'hello', u'world', u'!'],\n",
      " |      >>>           spaces=[True, False, False])\n",
      " |  \n",
      " |  DOCS: https://spacy.io/api/doc\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bytes__(...)\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      Get a `Token` or `Span` object.\n",
      " |      \n",
      " |      i (int or tuple) The index of the token, or the slice of the document\n",
      " |          to get.\n",
      " |      RETURNS (Token or Span): The token at `doc[i]]`, or the span at\n",
      " |          `doc[start : end]`.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> doc[i]\n",
      " |          Get the `Token` object at position `i`, where `i` is an integer.\n",
      " |          Negative indexing is supported, and follows the usual Python\n",
      " |          semantics, i.e. `doc[-2]` is `doc[len(doc) - 2]`.\n",
      " |      \n",
      " |          >>> doc[start : end]]\n",
      " |          Get a `Span` object, starting at position `start` and ending at\n",
      " |          position `end`, where `start` and `end` are token indices. For\n",
      " |          instance, `doc[2:5]` produces a span consisting of tokens 2, 3 and\n",
      " |          4. Stepped slices (e.g. `doc[start : end : step]`) are not\n",
      " |          supported, as `Span` objects must be contiguous (cannot have gaps).\n",
      " |          You can use negative indices and open-ended ranges, which have\n",
      " |          their normal Python semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#getitem\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      Create a Doc object.\n",
      " |      \n",
      " |      vocab (Vocab): A vocabulary object, which must match any models you\n",
      " |          want to use (e.g. tokenizer, parser, entity recognizer).\n",
      " |      words (list or None): A list of unicode strings to add to the document\n",
      " |          as words. If `None`, defaults to empty list.\n",
      " |      spaces (list or None): A list of boolean values, of the same length as\n",
      " |          words. True means that the word is followed by a space, False means\n",
      " |          it is not. If `None`, defaults to `[True]*len(words)`\n",
      " |      user_data (dict or None): Optional extra data to attach to the Doc.\n",
      " |      RETURNS (Doc): The newly constructed object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#init\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      Iterate over `Token`  objects, from which the annotations can be\n",
      " |      easily accessed. This is the main way of accessing `Token` objects,\n",
      " |      which are the main way annotations are accessed from Python. If faster-\n",
      " |      than-Python speeds are required, you can instead access the annotations\n",
      " |      as a numpy array, or access the underlying C data directly from Cython.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#iter\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      The number of tokens in the document.\n",
      " |      \n",
      " |      RETURNS (int): The number of tokens in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#len\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |  \n",
      " |  char_span(...)\n",
      " |      Create a `Span` object from the slice\n",
      " |      `doc.text[start_idx : end_idx]`. Returns None if no valid `Span` can be\n",
      " |      created.\n",
      " |      \n",
      " |      doc (Doc): The parent document.\n",
      " |      start_idx (int): The index of the first character of the span.\n",
      " |      end_idx (int): The index of the first character after the span.\n",
      " |      label (uint64 or string): A label to attach to the Span, e.g. for\n",
      " |          named entities.\n",
      " |      kb_id (uint64 or string):  An ID from a KB to capture the meaning of a\n",
      " |          named entity.\n",
      " |      vector (ndarray[ndim=1, dtype='float32']): A meaning representation of\n",
      " |          the span.\n",
      " |      alignment_mode (str): How character indices are aligned to token\n",
      " |          boundaries. Options: \"strict\" (character indices must be aligned\n",
      " |          with token boundaries), \"contract\" (span of all tokens completely\n",
      " |          within the character span), \"expand\" (span of all tokens at least\n",
      " |          partially covered by the character span). Defaults to \"strict\".\n",
      " |      RETURNS (Span): The newly constructed object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#char_span\n",
      " |  \n",
      " |  count_by(...)\n",
      " |      Count the frequencies of a given attribute. Produces a dict of\n",
      " |      `{attribute (int): count (ints)}` frequencies, keyed by the values of\n",
      " |      the given attribute ID.\n",
      " |      \n",
      " |      attr_id (int): The attribute ID to key the counts.\n",
      " |      RETURNS (dict): A dictionary mapping attributes to integer counts.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#count_by\n",
      " |  \n",
      " |  extend_tensor(...)\n",
      " |      Concatenate a new tensor onto the doc.tensor object.\n",
      " |      \n",
      " |      The doc.tensor attribute holds dense feature vectors\n",
      " |      computed by the models in the pipeline. Let's say a\n",
      " |      document with 30 words has a tensor with 128 dimensions\n",
      " |      per word. doc.tensor.shape will be (30, 128). After\n",
      " |      calling doc.extend_tensor with an array of shape (30, 64),\n",
      " |      doc.tensor == (30, 192).\n",
      " |  \n",
      " |  from_array(...)\n",
      " |      Load attributes from a numpy array. Write to a `Doc` object, from an\n",
      " |      `(M, N)` array of attributes.\n",
      " |      \n",
      " |      attrs (list) A list of attribute ID ints.\n",
      " |      array (numpy.ndarray[ndim=2, dtype='int32']): The attribute values.\n",
      " |      RETURNS (Doc): Itself.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_array\n",
      " |  \n",
      " |  from_bytes(...)\n",
      " |      Deserialize, i.e. import the document contents from a binary string.\n",
      " |      \n",
      " |      data (bytes): The string to load from.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (Doc): Itself.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_bytes\n",
      " |  \n",
      " |  from_disk(...)\n",
      " |      Loads state from a directory. Modifies the object in place and\n",
      " |      returns it.\n",
      " |      \n",
      " |      path (unicode or Path): A path to a directory. Paths may be either\n",
      " |          strings or `Path`-like objects.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (Doc): The modified `Doc` object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_disk\n",
      " |  \n",
      " |  get_lca_matrix(...)\n",
      " |      Calculates a matrix of Lowest Common Ancestors (LCA) for a given\n",
      " |      `Doc`, where LCA[i, j] is the index of the lowest common ancestor among\n",
      " |      token i and j.\n",
      " |      \n",
      " |      RETURNS (np.array[ndim=2, dtype=numpy.int32]): LCA matrix with shape\n",
      " |          (n, n), where n = len(self).\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#get_lca_matrix\n",
      " |  \n",
      " |  merge(...)\n",
      " |      Retokenize the document, such that the span at\n",
      " |      `doc.text[start_idx : end_idx]` is merged into a single token. If\n",
      " |      `start_idx` and `end_idx `do not mark start and end token boundaries,\n",
      " |      the document remains unchanged.\n",
      " |      \n",
      " |      start_idx (int): Character index of the start of the slice to merge.\n",
      " |      end_idx (int): Character index after the end of the slice to merge.\n",
      " |      **attributes: Attributes to assign to the merged token. By default,\n",
      " |          attributes are inherited from the syntactic root of the span.\n",
      " |      RETURNS (Token): The newly merged token, or `None` if the start and end\n",
      " |          indices did not fall at token boundaries.\n",
      " |  \n",
      " |  print_tree(...)\n",
      " |  \n",
      " |  retokenize(...)\n",
      " |      Context manager to handle retokenization of the Doc.\n",
      " |      Modifications to the Doc's tokenization are stored, and then\n",
      " |      made all at once when the context manager exits. This is\n",
      " |      much more efficient, and less error-prone.\n",
      " |      \n",
      " |      All views of the Doc (Span and Token) created before the\n",
      " |      retokenization are invalidated, although they may accidentally\n",
      " |      continue to work.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#retokenize\n",
      " |      USAGE: https://spacy.io/usage/linguistic-features#retokenization\n",
      " |  \n",
      " |  similarity(...)\n",
      " |      Make a semantic similarity estimate. The default estimate is cosine\n",
      " |      similarity using an average of word vectors.\n",
      " |      \n",
      " |      other (object): The object to compare with. By default, accepts `Doc`,\n",
      " |          `Span`, `Token` and `Lexeme` objects.\n",
      " |      RETURNS (float): A scalar similarity score. Higher is more similar.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#similarity\n",
      " |  \n",
      " |  to_array(...)\n",
      " |      Export given token attributes to a numpy `ndarray`.\n",
      " |      If `attr_ids` is a sequence of M attributes, the output array will be\n",
      " |      of shape `(N, M)`, where N is the length of the `Doc` (in tokens). If\n",
      " |      `attr_ids` is a single attribute, the output shape will be (N,). You\n",
      " |      can specify attributes by integer ID (e.g. spacy.attrs.LEMMA) or\n",
      " |      string name (e.g. 'LEMMA' or 'lemma').\n",
      " |      \n",
      " |      attr_ids (list[]): A list of attributes (int IDs or string names).\n",
      " |      RETURNS (numpy.ndarray[long, ndim=2]): A feature matrix, with one row\n",
      " |          per word, and one column per attribute indicated in the input\n",
      " |          `attr_ids`.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
      " |          >>> doc = nlp(text)\n",
      " |          >>> # All strings mapped to integers, for easy export to numpy\n",
      " |          >>> np_array = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])\n",
      " |  \n",
      " |  to_bytes(...)\n",
      " |      Serialize, i.e. export the document contents to a binary string.\n",
      " |      \n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (bytes): A losslessly serialized copy of the `Doc`, including\n",
      " |          all annotations.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_bytes\n",
      " |  \n",
      " |  to_disk(...)\n",
      " |      Save the current state to a directory.\n",
      " |      \n",
      " |      path (unicode or Path): A path to a directory, which will be created if\n",
      " |          it doesn't exist. Paths may be either strings or Path-like objects.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_disk\n",
      " |  \n",
      " |  to_json(...)\n",
      " |      Convert a Doc to JSON. The format it produces will be the new format\n",
      " |      for the `spacy train` command (not implemented yet).\n",
      " |      \n",
      " |      underscore (list): Optional list of string names of custom doc._.\n",
      " |      attributes. Attribute values need to be JSON-serializable. Values will\n",
      " |      be added to an \"_\" key in the data, e.g. \"_\": {\"foo\": \"bar\"}.\n",
      " |      RETURNS (dict): The data in spaCy's JSON format.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_json\n",
      " |  \n",
      " |  to_utf8_array(...)\n",
      " |      Encode word strings to utf8, and export to a fixed-width array\n",
      " |      of characters. Characters are placed into the array in the order:\n",
      " |          0, -1, 1, -2, etc\n",
      " |      For example, if the array is sliced array[:, :8], the array will\n",
      " |      contain the first 4 characters and last 4 characters of each word ---\n",
      " |      with the middle characters clipped out. The value 255 is used as a pad\n",
      " |      value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  get_extension(...) from builtins.type\n",
      " |      Look up a previously registered extension by name.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#get_extension\n",
      " |  \n",
      " |  has_extension(...) from builtins.type\n",
      " |      Check whether an extension has been registered.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (bool): Whether the extension has been registered.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#has_extension\n",
      " |  \n",
      " |  remove_extension(...) from builtins.type\n",
      " |      Remove a previously registered extension.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n",
      " |          removed extension.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#remove_extension\n",
      " |  \n",
      " |  set_extension(...) from builtins.type\n",
      " |      Define a custom attribute which becomes available as `Doc._`.\n",
      " |      \n",
      " |      name (unicode): Name of the attribute to set.\n",
      " |      default: Optional default value of the attribute.\n",
      " |      getter (callable): Optional getter function.\n",
      " |      setter (callable): Optional setter function.\n",
      " |      method (callable): Optional method for method extension.\n",
      " |      force (bool): Force overwriting existing attribute.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#set_extension\n",
      " |      USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  cats\n",
      " |  \n",
      " |  doc\n",
      " |  \n",
      " |  ents\n",
      " |      The named entities in the document. Returns a tuple of named entity\n",
      " |      `Span` objects, if the entity recognizer has been applied.\n",
      " |      \n",
      " |      RETURNS (tuple): Entities in the document, one `Span` per entity.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#ents\n",
      " |  \n",
      " |  has_vector\n",
      " |      A boolean value indicating whether a word vector is associated with\n",
      " |      the object.\n",
      " |      \n",
      " |      RETURNS (bool): Whether a word vector is associated with the object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#has_vector\n",
      " |  \n",
      " |  is_nered\n",
      " |      Check if the document has named entities set. Will return True if\n",
      " |      *any* of the tokens has a named entity tag set (even if the others are\n",
      " |      unknown values), or if the document is empty.\n",
      " |  \n",
      " |  is_parsed\n",
      " |  \n",
      " |  is_sentenced\n",
      " |      Check if the document has sentence boundaries assigned. This is\n",
      " |      defined as having at least one of the following:\n",
      " |      \n",
      " |      a) An entry \"sents\" in doc.user_hooks\";\n",
      " |      b) Doc.is_parsed is set to True;\n",
      " |      c) At least one token other than the first where sent_start is not None.\n",
      " |  \n",
      " |  is_tagged\n",
      " |  \n",
      " |  lang\n",
      " |      RETURNS (uint64): ID of the language of the doc's vocabulary.\n",
      " |  \n",
      " |  lang_\n",
      " |      RETURNS (unicode): Language of the doc's vocabulary, e.g. 'en'.\n",
      " |  \n",
      " |  mem\n",
      " |  \n",
      " |  noun_chunks\n",
      " |      Iterate over the base noun phrases in the document. Yields base\n",
      " |      noun-phrase #[code Span] objects, if the document has been\n",
      " |      syntactically parsed. A base noun phrase, or \"NP chunk\", is a noun\n",
      " |      phrase that does not permit other NPs to be nested within it – so no\n",
      " |      NP-level coordination, no prepositional phrases, and no relative\n",
      " |      clauses.\n",
      " |      \n",
      " |      YIELDS (Span): Noun chunks in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#noun_chunks\n",
      " |  \n",
      " |  noun_chunks_iterator\n",
      " |  \n",
      " |  sentiment\n",
      " |  \n",
      " |  sents\n",
      " |      Iterate over the sentences in the document. Yields sentence `Span`\n",
      " |      objects. Sentence spans have no label. To improve accuracy on informal\n",
      " |      texts, spaCy calculates sentence boundaries from the syntactic\n",
      " |      dependency parse. If the parser is disabled, the `sents` iterator will\n",
      " |      be unavailable.\n",
      " |      \n",
      " |      YIELDS (Span): Sentences in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#sents\n",
      " |  \n",
      " |  tensor\n",
      " |  \n",
      " |  text\n",
      " |      A unicode representation of the document text.\n",
      " |      \n",
      " |      RETURNS (unicode): The original verbatim text of the document.\n",
      " |  \n",
      " |  text_with_ws\n",
      " |      An alias of `Doc.text`, provided for duck-type compatibility with\n",
      " |      `Span` and `Token`.\n",
      " |      \n",
      " |      RETURNS (unicode): The original verbatim text of the document.\n",
      " |  \n",
      " |  user_data\n",
      " |  \n",
      " |  user_hooks\n",
      " |  \n",
      " |  user_span_hooks\n",
      " |  \n",
      " |  user_token_hooks\n",
      " |  \n",
      " |  vector\n",
      " |      A real-valued meaning representation. Defaults to an average of the\n",
      " |      token vectors.\n",
      " |      \n",
      " |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n",
      " |          representing the document's semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#vector\n",
      " |  \n",
      " |  vector_norm\n",
      " |      The L2 norm of the document's vector representation.\n",
      " |      \n",
      " |      RETURNS (float): The L2 norm of the vector representation.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#vector_norm\n",
      " |  \n",
      " |  vocab\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "抽出できる固有表現の種類ですが、上記の結果から推察するに、こちら*6だと思います。とは言っても GiNZA がどのようなデータで学習したか確認できてないので、はっきりしたことは言えません。ただ、どのような固有表現を抽出したいかは、要件次第のところもあります。GiNZA の git リポジトリに含まれる学習スクリプト*7を見ると、こちら*8 の train_data の形式で学習データを食わせてやれば良さそうなので、興味のある人は頑張ってみてください。spaCy のドキュメント*9によれば少なくとも数百件は必要とのことです。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 係り受け関係表示\r\n",
    "from nltk import Tree\r\n",
    "\r\n",
    "# tree表示するトークンのフォーマット\r\n",
    "def token_format(tk):\r\n",
    "    # トークンのorth_、dep_、pos_の３つをトークンの情報として含める\r\n",
    "    return \"_\".join([tk.orth_, tk.dep_, tk.pos_])\r\n",
    "\r\n",
    "# tree表示する関数\r\n",
    "def to_nltk_tree(node):\r\n",
    "    if node.n_lefts + node.n_rights > 0:\r\n",
    "        return Tree(token_format(node), [to_nltk_tree(child) for child in node.children])\r\n",
    "    else:\r\n",
    "        return token_format(node)\r\n",
    "\r\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                  混ぜる_ROOT_VERB                                                                            \n",
      "       _________________________________________________________________|_________________________________________________                                  \n",
      "      |                       |                                   たまねぎ_obl_NOUN                                       卵_obj_NOUN                           \n",
      "      |                       |                            _____________|____________                           __________|___________                      \n",
      "      |                       |                           |                     冷まし_acl_VERB                   |                 牛乳_nmod_NOUN              \n",
      "      |                       |                           |              ____________|_____________            |           ___________|_____________        \n",
      "      |                  ひき肉_obl_NOUN                     |             |                    炒め_advcl_VERB     |          |                   パン粉_nmod_NOUN\n",
      "      |            ___________|_____________              |             |                          |           |          |                         |       \n",
      "。_punct_PUNCT に_case_ADP              、_punct_PUNCT 、_punct_PUNCT   た_aux_AUX                 て_mark_SCONJ を_case_ADP と_case_ADP                と_case_ADP \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 係り受け関係解析：グラフ表示\r\n",
    "from spacy import displacy\r\n",
    "\r\n",
    "for sent in doc.sents:\r\n",
    "    svg = displacy.render(sent, style=\"dep\", options={\"compact\":True})"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ja\" id=\"7119a858b5f0421498b960b51229ed37-0\" class=\"displacy\" width=\"2150\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ひき肉</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">に、</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">炒め</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">て</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">冷まし</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">た</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">たまねぎ、</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">パン粉</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">と</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">牛乳</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">と</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">卵</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">を</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\">混ぜる。</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-0\" stroke-width=\"2px\" d=\"M62,302.0 62,202.0 2000.0,202.0 2000.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,304.0 L58,296.0 66,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-1\" stroke-width=\"2px\" d=\"M62,302.0 62,277.0 191.0,277.0 191.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M191.0,304.0 L195.0,296.0 187.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-2\" stroke-width=\"2px\" d=\"M362,302.0 362,252.0 644.0,252.0 644.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,304.0 L358,296.0 366,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-3\" stroke-width=\"2px\" d=\"M362,302.0 362,277.0 491.0,277.0 491.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M491.0,304.0 L495.0,296.0 487.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-4\" stroke-width=\"2px\" d=\"M662,302.0 662,252.0 944.0,252.0 944.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,304.0 L658,296.0 666,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-5\" stroke-width=\"2px\" d=\"M662,302.0 662,277.0 791.0,277.0 791.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M791.0,304.0 L795.0,296.0 787.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-6\" stroke-width=\"2px\" d=\"M962,302.0 962,227.0 1997.0,227.0 1997.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,304.0 L958,296.0 966,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-7\" stroke-width=\"2px\" d=\"M1112,302.0 1112,252.0 1394.0,252.0 1394.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1112,304.0 L1108,296.0 1116,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-8\" stroke-width=\"2px\" d=\"M1112,302.0 1112,277.0 1241.0,277.0 1241.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1241.0,304.0 L1245.0,296.0 1237.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-9\" stroke-width=\"2px\" d=\"M1412,302.0 1412,252.0 1694.0,252.0 1694.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1412,304.0 L1408,296.0 1416,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-10\" stroke-width=\"2px\" d=\"M1412,302.0 1412,277.0 1541.0,277.0 1541.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1541.0,304.0 L1545.0,296.0 1537.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-11\" stroke-width=\"2px\" d=\"M1712,302.0 1712,252.0 1994.0,252.0 1994.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1712,304.0 L1708,296.0 1716,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7119a858b5f0421498b960b51229ed37-0-12\" stroke-width=\"2px\" d=\"M1712,302.0 1712,277.0 1841.0,277.0 1841.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7119a858b5f0421498b960b51229ed37-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1841.0,304.0 L1845.0,296.0 1837.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 係り受け関係解析：料理手順\r\n",
    "\r\n",
    "nlp = spacy.load('ja_ginza')\r\n",
    "\r\n",
    "instruction_list = [\r\n",
    "  \"ひき肉に、炒めて冷めたたまねぎ、パン粉と牛乳と卵を混ぜる。塩、胡椒、カレー粉を加えて、さらによく練る。小判上に成形して裏表にパン粉をつける。真ん中をくぼます。\",\r\n",
    "  \"［ポーチドエッグ］水、酢、塩を入れて沸騰させ、割った卵を鍋の縁からゆっくり入れる。卵が茹で上がったら水に取り出す。\",\r\n",
    "  \"赤ワインを火に掛けアルコールを飛ばし、水、トマトケチャップ、トマトピューレを合わせ、ソースを作る。\",\r\n",
    "  \"熱したフライパンにサラダ油を入れ、中火でハンバーグのパテを入れる。1分程度焼く、裏返し、裏も1分程度焼く。ハンバーグを取り出し、フライパンの油を捨てる。\",\r\n",
    "  \"中火にし、玉葱の輪切りを入れる。玉葱が焼けたら裏返し、ハンバーグを上に置く。のせたハンバーグにソースの材料を加え、フライパンにフタをし2～3分蒸し焼きにする。\",\r\n",
    "  \"竹串で突き透明の肉汁が出たら取り出す。肉汁を煮立て、塩胡椒を加えソースを完成させる。ハンバーグを皿に盛り、玉葱の輪切りとポーチドエッグをのせ、ソースをかける。\"\r\n",
    "]\r\n",
    "\r\n",
    "# instruction = ''.join(instruction_list)\r\n",
    "docs = list(nlp.pipe(instruction_list))\r\n",
    "\r\n",
    "# for doc in docs:\r\n",
    "#   for ent in doc.ents:\r\n",
    "#     print(ent.text, ent.start_char, ent.end_char, ent.label_)\r\n",
    "\r\n",
    "for sent in doc.sents:\r\n",
    "    svg = displacy.render(sent, style=\"dep\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ja\" id=\"c4d8aa95e9e1440a87467d20f8117011-0\" class=\"displacy\" width=\"2500\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ひき肉</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">に、</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">炒め</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">て</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">冷まし</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">た</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">たまねぎ、</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">パン粉</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">と</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">牛乳</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">と</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">卵</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">を</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">混ぜる。</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 2325.0,2.0 2325.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,89.5 2320.0,89.5 2320.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-8\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-10\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-11\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,177.0 2315.0,177.0 2315.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4d8aa95e9e1440a87467d20f8117011-0-12\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4d8aa95e9e1440a87467d20f8117011-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "703bbbeedfcbeab203e322e73325805c9ac8ffb4b5321a34c42f421369651d04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}