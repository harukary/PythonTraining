{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "15分でできる日本語Word2Vec https://qiita.com/makaishi2/items/63b7986f6da93dc55edd"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# zipファイルダウンロード\r\n",
    "url = 'https://www.aozora.gr.jp/cards/000148/files/794_ruby_4237.zip'\r\n",
    "zip = 'data/794_ruby_4237.zip'\r\n",
    "import urllib.request\r\n",
    "urllib.request.urlretrieve(url, zip)\r\n",
    "\r\n",
    "# ダウンロードしたzipの解凍\r\n",
    "import zipfile\r\n",
    "with zipfile.ZipFile(zip, 'r') as myzip:\r\n",
    "    myzip.extractall()\r\n",
    "    # 解凍後のファイルからデータ読み込み\r\n",
    "    for myfile in myzip.infolist():\r\n",
    "        # 解凍後ファイル名取得\r\n",
    "        filename = myfile.filename\r\n",
    "        # ファイルオープン時にencodingを指定してsjisの変換をする\r\n",
    "        with open(filename, encoding='sjis') as file:\r\n",
    "            text = file.read()\r\n",
    "\r\n",
    "# ファイル整形\r\n",
    "import re\r\n",
    "# ヘッダ部分の除去\r\n",
    "text = re.split('\\-{5,}',text)[2]\r\n",
    "# フッタ部分の除去\r\n",
    "text = re.split('底本：',text)[0]\r\n",
    "# | の除去\r\n",
    "text = text.replace('|', '')\r\n",
    "# ルビの削除\r\n",
    "text = re.sub('《.+?》', '', text)\r\n",
    "# 入力注の削除\r\n",
    "text = re.sub('［＃.+?］', '',text)\r\n",
    "# 空行の削除\r\n",
    "text = re.sub('\\n\\n', '\\n', text) \r\n",
    "text = re.sub('\\r', '', text)\r\n",
    "\r\n",
    "# 整形結果確認\r\n",
    "\r\n",
    "# 頭の100文字の表示 \r\n",
    "print(text[:100])\r\n",
    "# 見やすくするため、空行 \r\n",
    "print()\r\n",
    "print()\r\n",
    "# 後ろの100文字の表示 \r\n",
    "print(text[-100:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "一\n",
      "　うとうととして目がさめると女はいつのまにか、隣のじいさんと話を始めている。このじいさんはたしかに前の前の駅から乗ったいなか者である。発車まぎわに頓狂な声を出して駆け込んで来て、いきなり肌をぬい\n",
      "\n",
      "\n",
      "評に取りかかる。与次郎だけが三四郎のそばへ来た。\n",
      "「どうだ森の女は」\n",
      "「森の女という題が悪い」\n",
      "「じゃ、なんとすればよいんだ」\n",
      "　三四郎はなんとも答えなかった。ただ口の中で迷羊、迷羊と繰り返した。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Janomeのロード\r\n",
    "from janome.tokenizer import Tokenizer\r\n",
    "\r\n",
    "# Tokenizerインスタンスの生成 \r\n",
    "t = Tokenizer()\r\n",
    "\r\n",
    "# テキストを引数として、形態素解析の結果、名詞・動詞・形容詞(原形)のみを配列で抽出する関数を定義 \r\n",
    "def extract_words(text):\r\n",
    "    tokens = t.tokenize(text)\r\n",
    "    return [token.base_form for token in tokens \r\n",
    "        if token.part_of_speech.split(',')[0] in['名詞', '動詞']]\r\n",
    "\r\n",
    "#  関数テスト\r\n",
    "# ret = extract_words('三四郎は京都でちょっと用があって降りたついでに。')\r\n",
    "# for word in ret:\r\n",
    "#    print(word)\r\n",
    "\r\n",
    "# 全体のテキストを句点('。')で区切った配列にする。 \r\n",
    "sentences = text.split('。')\r\n",
    "# それぞれの文章を単語リストに変換(処理に数分かかります)\r\n",
    "word_list = [extract_words(sentence) for sentence in sentences]\r\n",
    "\r\n",
    "# 結果の一部を確認 \r\n",
    "for word in word_list[0]:\r\n",
    "    print(word)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "一\n",
      "する\n",
      "目\n",
      "さめる\n",
      "女\n",
      "隣\n",
      "じいさん\n",
      "話\n",
      "始める\n",
      "いる\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "sentences=None, \r\n",
    "corpus_file=None, \r\n",
    "vector_size=100, \r\n",
    "alpha=0.025, \r\n",
    "window=5, \r\n",
    "min_count=5, \r\n",
    "max_vocab_size=None, \r\n",
    "sample=0.001, \r\n",
    "seed=1, \r\n",
    "workers=3, \r\n",
    "min_alpha=0.0001, \r\n",
    "sg=0, \r\n",
    "hs=0, \r\n",
    "negative=5, \r\n",
    "ns_exponent=0.75, \r\n",
    "cbow_mean=1, \r\n",
    "hashfxn=<built-in function hash>, \r\n",
    "epochs=5, \r\n",
    "null_word=0, \r\n",
    "trim_rule=None, \r\n",
    "sorted_vocab=1, \r\n",
    "batch_words=10000, \r\n",
    "compute_loss=False, \r\n",
    "callbacks=(), \r\n",
    "comment=None, \r\n",
    "max_final_vocab=None)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Word2Vecライブラリのロード\r\n",
    "from gensim.models import word2vec\r\n",
    "\r\n",
    "# size: 圧縮次元数\r\n",
    "# min_count: 出現頻度の低いものをカットする\r\n",
    "# window: 前後の単語を拾う際の窓の広さを決める\r\n",
    "# iter: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\r\n",
    "# model.wv.most_similarの結果が1に近いものばかりで、model.dict['wv']のベクトル値が小さい値ばかりの \r\n",
    "# ときは、学習回数が少ないと考えられます。\r\n",
    "# その場合、iterの値を大きくして、再度学習を行います。\r\n",
    "\r\n",
    "# 事前準備したword_listを使ってWord2Vecの学習実施\r\n",
    "# print(help(word2vec.Word2Vec()))\r\n",
    "model = word2vec.Word2Vec(word_list, vector_size=100,min_count=5,window=5,epochs=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(model.__dict__['wv']['世間'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.2514574   0.5983756  -0.1054646  -0.06951263 -0.4410906  -0.53059053\n",
      " -0.23402226  0.29629037 -0.10588566  0.2983036   0.33217373 -0.40734458\n",
      "  0.345004    0.6543715   0.41360125 -0.07991505 -0.17177987 -0.20790139\n",
      " -0.07939453 -0.53092706 -0.9385529   0.44570765  0.3491775  -0.94380504\n",
      "  0.28177077  0.01750118 -0.34375364 -0.27269652 -0.00292351 -0.7102562\n",
      "  0.47592166 -0.36076626  0.10864413 -0.28852105 -0.47496647  0.508098\n",
      " -0.61526084 -0.30691984 -0.24021763  0.06906699  0.5480436  -0.16006823\n",
      " -0.44741383 -0.6408411  -0.5850065   0.80511105 -0.14887643 -0.39739117\n",
      "  0.6046842  -0.37735268  0.65816826 -0.37087408  0.7283094  -0.3201044\n",
      "  0.23423342 -0.80463755  0.47638243  0.16982616 -0.5547485   0.58759356\n",
      " -0.7584049   0.2320579  -0.80850285 -0.5472746  -0.98315924  0.2319699\n",
      " -0.10905959 -0.6251506   0.12024964  0.4231289  -0.46065265 -0.5022147\n",
      " -0.3022688  -0.08488819  0.47481737 -0.17572248 -0.08048092  0.49595952\n",
      "  0.29220933  0.27159315 -0.87362033  0.20104706 -0.29757664 -0.04458126\n",
      " -0.20799522 -0.2687289  -0.18802814  0.02978987  0.4433415   0.37752438\n",
      " -0.41700232 -0.15117355  0.06355042 -0.9298258   0.1604079  -0.08226848\n",
      " -0.21444732 -0.11933289  0.07904197 -0.12036869]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 結果の確認2\r\n",
    "# 関数most_similarを使って「世間」の類似単語を調べます \r\n",
    "ret = model.wv.most_similar(positive=['世間']) \r\n",
    "for item in ret:\r\n",
    "    print(item[0], item[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "喝采 0.5834517478942871\n",
      "聞こえる 0.5745024085044861\n",
      "外国 0.5421279072761536\n",
      "自己 0.5368075370788574\n",
      "社会 0.49744874238967896\n",
      "決心 0.4789580702781677\n",
      "賛成 0.463409423828125\n",
      "有す 0.46222949028015137\n",
      "堪える 0.4474026560783386\n",
      "彼ら 0.4430335462093353\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "703bbbeedfcbeab203e322e73325805c9ac8ffb4b5321a34c42f421369651d04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}